(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[862],{4518:function(A,e,s){(window.__NEXT_P=window.__NEXT_P||[]).push(["/bodymove",function(){return s(4133)}])},7489:function(A,e){"use strict";e.Z={src:"/_next/static/media/bodymove.edc40faa.jpg",height:801,width:1429,blurDataURL:"data:image/jpeg;base64,/9j/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/2wBDAQoLCw4NDhwQEBw7KCIoOzs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozs7Ozv/wgARCAAEAAgDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAb/xAAUAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAGkA//EABYQAQEBAAAAAAAAAAAAAAAAAAIBEf/aAAgBAQABBQKHT//EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAIAQMBAT8Bf//EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAIAQIBAT8Bf//EABYQAQEBAAAAAAAAAAAAAAAAAAEAEf/aAAgBAQAGPwLVb//EABgQAQEAAwAAAAAAAAAAAAAAAAERAEFh/9oACAEBAAE/IRNBhvtz/9oADAMBAAIAAwAAABD/AP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAIAQMBAT8Qf//EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAIAQIBAT8Qf//EABkQAQACAwAAAAAAAAAAAAAAAAERIQBhcf/aAAgBAQABPxBTMW3Ft1tA4Rn/2Q==",blurWidth:8,blurHeight:4}},4133:function(A,e,s){"use strict";s.r(e);var a=s(5893),t=s(5675),i=s.n(t);s(7294);var o=s(7489),n=s(9352),c=s(1664),r=s.n(c);e.default=()=>(0,a.jsxs)("div",{className:"w-full",children:[(0,a.jsxs)("div",{className:"w-screen h-[50vh] relative",children:[(0,a.jsx)("div",{className:"absolute top-0 left-0 w-full h-[50vh] bg-black/70 z-10"}),(0,a.jsx)(i(),{className:"absolute z-1",layout:"fill",objectFit:"cover",src:o.Z,alt:"/"}),(0,a.jsxs)("div",{className:"absolute top-[70%] max-w-[1240px] w-full left-[50%] right-[50%] translate-x-[-50%] translate-y-[-50%] text-white z-10 p-2",children:[(0,a.jsx)("h2",{className:"py-2",children:"Body Movement Detection"}),(0,a.jsx)("h3",{children:"TensorFlow / Compter Vision / Mediapipe"})]})]}),(0,a.jsxs)("div",{className:"max-w-[1240px] mx-auto p-2 grid md:grid-cols-5 gap-8 py-8",children:[(0,a.jsxs)("div",{className:"col-span-4",children:[(0,a.jsx)("p",{children:"Project"}),(0,a.jsx)("h2",{className:"py-6",children:"Overview"}),(0,a.jsx)("p",{className:"text-justify text-xl",children:"This project involved developing a human body action recognition system using TensorFlow and MediaPipe for a game development studio. The system takes video clips of human body movements as input and outputs the corresponding movement type (right, left, jump, or crouch). The system was trained on a dataset of 400 video clips, each containing 15 frames of a specific movement. The system achieved a test accuracy of 98%, indicating its robustness and efficiency in classifying body movements. This project demonstrates the potential of TensorFlow and MediaPipe in developing real-time human body action recognition systems for various applications. I have done this project for Mars game studio. You can check the demo of the project in 3 Youtube videos I have recorded and uploaded on youtube!"}),(0,a.jsx)("a",{href:"https://github.com/hamednasr/TensorFlow-Projects/blob/main/body_move_recognition_for_game(mediapipe_abdomen)_15fps.ipynb",target:"_blank",rel:"noreferrer",children:(0,a.jsx)("button",{className:"px-8 py-2 mt-4 mr-8",children:"Code"})}),(0,a.jsx)("a",{href:"https://www.youtube.com/watch?v=7rAooRzc_qM&list=PLQaV6PCTazzo52mZbbRNaAzz6nTLqDtYS&index=2",target:"_blank",rel:"noreferrer",children:(0,a.jsx)("button",{className:"px-8 py-2 mt-4",children:"Demo"})})]}),(0,a.jsx)("div",{className:"col-span-4 md:col-span-1 shadow-xl shadow-gray-400 rounded-xl py-4",children:(0,a.jsxs)("div",{className:"p-2",children:[(0,a.jsx)("p",{className:"text-center font-bold pb-2",children:"Technologies"}),(0,a.jsxs)("div",{className:"grid grid-cols-3 md:grid-cols-1",children:[(0,a.jsxs)("p",{className:"text-gray-600 py-2 flex items-center",children:[(0,a.jsx)(n.Svj,{className:"pr-1"})," TensorFlow"]}),(0,a.jsxs)("p",{className:"text-gray-600 py-2 flex items-center",children:[(0,a.jsx)(n.Svj,{className:"pr-1"})," Compter Vision"]}),(0,a.jsxs)("p",{className:"text-gray-600 py-2 flex items-center",children:[(0,a.jsx)(n.Svj,{className:"pr-1"})," LSTM"]}),(0,a.jsxs)("p",{className:"text-gray-600 py-2 flex items-center",children:[(0,a.jsx)(n.Svj,{className:"pr-1"})," Mediapipe"]}),(0,a.jsxs)("p",{className:"text-gray-600 py-2 flex items-center",children:[(0,a.jsx)(n.Svj,{className:"pr-1"})," Numpy"]}),(0,a.jsxs)("p",{className:"text-gray-600 py-2 flex items-center",children:[(0,a.jsx)(n.Svj,{className:"pr-1"})," Scikit Learn"]})]})]})}),(0,a.jsx)(r(),{href:"/#projects",children:(0,a.jsx)("p",{className:"underline cursor-pointer",children:"Back"})})]})]})}},function(A){A.O(0,[937,774,888,179],function(){return A(A.s=4518)}),_N_E=A.O()}]);